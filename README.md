# LexiVoice â€“ AI-Powered Multilingual Legal Assistant
# ðŸ“‹ Module 2: RAG Pipeline - Simple To-Do List

---

## âœ… **Module 2.1: Prepare Legal Documents** (Day 1-2)

### **What we're doing:** Creating and organizing legal text data

#### **Tasks:**
1. âœ… Create 3 JSON files with legal documents
   - `backend/data/laws/india.json`
   - `backend/data/laws/canada.json`
   - `backend/data/laws/usa.json`

2. âœ… Create `backend/core/document_processor.py`
   - Function to load JSON files
   - Function to clean text (remove extra spaces, special characters)
   - Function to split documents into small chunks (paragraphs)

3. âœ… Create test script `backend/scripts/test_document_processing.py`
   - Test: Can we load documents?
   - Test: Are chunks the right size?
   - See statistics (how many chunks created)

**End Result:** Legal documents ready to be converted to embeddings

---

## âœ… **Module 2.2: Convert Text to Numbers (Embeddings)** (Day 3-4)

### **What we're doing:** Converting text chunks into numbers (vectors)

#### **Tasks:**
1. âœ… Create `backend/core/embeddings.py`
   - Load sentence-transformers model
   - Function: text â†’ list of numbers (embedding)
   - Test with sample text

2. âœ… Create `backend/core/retriever.py`
   - Build FAISS index (database of vectors)
   - Function to save index to disk
   - Function to load index from disk
   - Function to search similar chunks

3. âœ… Create `backend/scripts/build_vector_store.py`
   - Run once to create FAISS indexes for all countries
   - Save indexes to `backend/data/faiss_indexes/`

**End Result:** Searchable database of legal document vectors

---

## âœ… **Module 2.3: AI Integration (LLM)** (Day 5-6)

### **What we're doing:** Connecting to Groq AI to generate answers

#### **Tasks:**
1. âœ… Create `backend/core/llm_handler.py`
   - Connect to Groq API
   - Create prompt template (how to ask AI)
   - Function: question + documents â†’ AI answer
   - Parse AI response (extract answer, reasoning, sources)

2. âœ… Test AI responses
   - Test with sample question
   - Verify citations are included
   - Check answer quality

**End Result:** Working AI that can answer questions using documents

---

## âœ… **Module 2.4: Complete RAG Pipeline + API** (Day 7)

### **What we're doing:** Connect everything together in one API endpoint

#### **Tasks:**
1. âœ… Create `backend/routers/chat.py`
   - POST `/api/v1/chat` endpoint
   - Full flow:
     - Receive question
     - Search documents (retriever)
     - Generate answer (LLM)
     - Save to database (query log)
     - Return response

2. âœ… Update `backend/main.py`
   - Add chat router to FastAPI app

3. âœ… Test complete flow
   - Send test questions via API
   - Verify responses include answer + sources
   - Check database logs

**End Result:** Working RAG API endpoint!

---

## ðŸ“Š **Summary: 4 Simple Steps**

```
Step 2.1: Prepare Documents
   â†“
   Legal text split into small chunks
   â†“
Step 2.2: Create Embeddings
   â†“
   Chunks converted to numbers, stored in FAISS
   â†“
Step 2.3: Connect AI
   â†“
   Groq AI can generate answers from documents
   â†“
Step 2.4: Build API
   â†“
   Question â†’ Search â†’ AI â†’ Answer (with sources)
```

---

## ðŸŽ¯ **Let's Start with Step 2.1!**

Ready to create the legal document files? I'll give you:
- âœ… The 3 JSON files (copy-paste ready)
- âœ… Simple document processor code
- âœ… Test script to verify it works

**Should I proceed with Step 2.1 now?** 

Say "yes" and I'll give you the first set of files to create! ðŸš€





Features to be done:
main ui page work
faiss indexs issue
many languages isssue
